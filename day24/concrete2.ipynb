{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moon_dataset(n_samples=1000):\n",
    "    # Create moon-shaped data\n",
    "    X, y = make_moons(n_samples=n_samples, noise=0.1)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    X = torch.FloatTensor(X)\n",
    "    # Convert to one-hot encoding\n",
    "    y_onehot = torch.zeros(n_samples, 2)\n",
    "    y_onehot[range(n_samples), y] = 1\n",
    "    \n",
    "    return X, y_onehot\n",
    "\n",
    "# Create and split the data\n",
    "X, y = create_moon_dataset()  # or create_moon_dataset(1000)\n",
    "\n",
    "# Split into train and test\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7101,  1.3707],\n",
       "        [ 0.6174, -0.8954],\n",
       "        [-0.0175,  1.2468],\n",
       "        [-0.5357, -0.9086],\n",
       "        [-1.1670,  1.4153]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEAT = 2\n",
    "OUT_FEAT = 2\n",
    "\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    \"\"\"Simple MLP with PyTorch\"\"\"\n",
    "\n",
    "    def __init__(self, n_hidden = 30):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features=IN_FEAT, out_features=n_hidden)\n",
    "        self.fc2 = torch.nn.Linear(in_features=n_hidden, out_features=n_hidden)\n",
    "        self.fc3 = torch.nn.Linear(in_features=n_hidden, out_features=OUT_FEAT)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=10):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.4718\n",
      "Test accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, X_train, y_train)\n",
    "\n",
    "# Test predictions\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test)\n",
    "    accuracy = ((test_predictions.argmax(dim=1) == y_test.argmax(dim=1)).float().mean())\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas import nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.quant import Int8ActPerTensorFloat, Int8WeightPerTensorFloat\n",
    "\n",
    "N_BITS = 4\n",
    "IN_FEAT = 2\n",
    "OUT_FEAT = 2\n",
    "    \n",
    "class QuantSimpleNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_hidden = 30,\n",
    "        qlinear_args={\n",
    "            \"weight_bit_width\": N_BITS,\n",
    "            \"weight_quant\": Int8WeightPerTensorFloat,\n",
    "            \"bias\": True,\n",
    "            \"bias_quant\": None,\n",
    "            \"narrow_range\": True\n",
    "        },\n",
    "        qidentity_args={\"bit_width\": N_BITS, \"act_quant\": Int8ActPerTensorFloat},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.quant_inp = qnn.QuantIdentity(**qidentity_args)\n",
    "        self.fc1 = qnn.QuantLinear(IN_FEAT, n_hidden, **qlinear_args)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=qidentity_args[\"bit_width\"])\n",
    "        self.fc2 = qnn.QuantLinear(n_hidden, n_hidden, **qlinear_args)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=qidentity_args[\"bit_width\"])\n",
    "        self.fc3 = qnn.QuantLinear(n_hidden, OUT_FEAT, **qlinear_args)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, qnn.QuantLinear):\n",
    "                torch.nn.init.uniform_(m.weight.data, -1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant_inp(x)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 27.6828\n",
      "Test accuracy: 0.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivw/Workspace/Programming_Projects/30DaysOfFLCode/.concrete/lib/python3.10/site-packages/torch/_tensor.py:1419: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/c10/core/TensorImpl.h:1924.)\n",
      "  return super().rename(names)\n"
     ]
    }
   ],
   "source": [
    "qntmodel = QuantSimpleNet()\n",
    "train_model(qntmodel, X_train, y_train)\n",
    "\n",
    "# Test predictions\n",
    "with torch.no_grad():\n",
    "    test_predictions = qntmodel(X_test)\n",
    "    accuracy = ((test_predictions.argmax(dim=1) == y_test.argmax(dim=1)).float().mean())\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concrete.ml.torch.compile import compile_brevitas_qat_model\n",
    "\n",
    "N_FEAT = 2\n",
    "\n",
    "torch_input = torch.randn(100, N_FEAT)\n",
    "quantized_module = compile_brevitas_qat_model(\n",
    "    qntmodel, # our model\n",
    "    torch_input, # a representative input-set to be used for both quantization and compilation\n",
    "    rounding_threshold_bits={\"n_bits\": N_BITS, \"method\": \"approximate\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = quantized_module.forward(X_test.numpy(), fhe=\"execute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5350)\n"
     ]
    }
   ],
   "source": [
    "print((test_predictions.argmax(dim=1) == y_test.argmax(dim=1)).float().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".concrete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
